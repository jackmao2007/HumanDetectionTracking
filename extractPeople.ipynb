{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"extractPeople.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"72gZvbv7fnf0","colab_type":"text"},"cell_type":"markdown","source":["Section 0"]},{"metadata":{"id":"XRSxjm45MhgT","colab_type":"code","colab":{}},"cell_type":"code","source":["# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Helper libraries\n","from os import listdir\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab import drive\n","import random\n","from skimage import data\n","from skimage.transform import pyramid_gaussian, pyramid_expand\n","\n","\n","drive.mount('/content/gdrive')\n","gdrive = \"/content/gdrive/My Drive/ProjectHumanDetection/\"\n","runpath = 'googleData/download_run'\n","walkpath = 'googleData/download_walk'\n","standpath ='googleData/download_stand'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ehEgB-DtfqaO","colab_type":"text"},"cell_type":"markdown","source":["Section 1"]},{"metadata":{"id":"NN1MbbhdUc66","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_hog_descriptors(images):\n","  \"\"\" gets the hog descriptors for each of the images, and returns a\n","  ndarray containing all the descriptors\n","  \"\"\"\n","  img_count = images.shape[0]\n","  hog = cv2.HOGDescriptor()\n","  results = np.zeros((img_count, 3780, 1))\n","  for i in range(img_count):\n","    results[i, :, :] = hog.compute(images[i, :, :].astype(np.uint8))\n","  return results\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-vv8ViXjfr9R","colab_type":"text"},"cell_type":"markdown","source":["Section 2"]},{"metadata":{"id":"qGmGS22KbDYR","colab_type":"code","colab":{}},"cell_type":"code","source":["def non_max_supression(boxes, thres=0.5):\n","  \"\"\" input is a list of boxes with detection scores\n","  list(list(y_start, y_end, x_start, x_end, prediction_score))\n","  return a list of boxes with overlaping supressed\n","  \"\"\"\n","  def take_score(lst):\n","    return lst[4]\n","  \n","  top_score = sorted(boxes, key=take_score)\n","  good_boxes = []\n","  while top_score != []:\n","    # get the top score box\n","    good = top_score.pop()\n","    good_area = (good[1] - good[0]) * (good[3] - good[2])\n","    i = len(top_score) - 1\n","    while i >= 0:\n","      check = top_score[i]\n","      check_area = (check[1] - check[0]) * (check[3] - check[2])\n","      xx1 = max(good[2], check[2])\n","      yy1 = max(good[0], check[0])\n","      xx2 = min(good[3], check[3])\n","      yy2 = min(good[1], check[1])\n","      overlap = max(0,(yy2 - yy1)) * max(0, (xx2 - xx1))\n","      if overlap / (good_area + check_area - overlap) > thres:\n","        top_score.pop(i)\n","      i -= 1\n","    good_boxes.append(good)\n","  return good_boxes\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"nCZUXn4Rftk8","colab_type":"text"},"cell_type":"markdown","source":["Section 3"]},{"metadata":{"id":"g8OAqV_mM-L7","colab_type":"code","colab":{}},"cell_type":"code","source":["def find_detections(img, human_model, pose_model, image_scaling):\n","  \"\"\" draw_the detection boxes on the img, detect using human_model and \n","  pose_model. Use sliding box on image pyrimid with total of 8 layers\n","  with image_scaling \n","  \"\"\"\n","  box_l = 128\n","  box_w = 64\n","  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","  l, w = gray.shape\n","  # detection boxes\n","  people = []\n","  # scalling of the image pyrimid\n","  scalor = image_scaling\n","  # get one bigger layer to detect smaller people\n","  big = cv2.resize(gray, (int(w * scalor), int(l * scalor)))\n","  pyrimid = [big] + list(pyramid_gaussian(gray, max_layer=6, downscale=scalor))\n","  # sliding box \n","  for i in range(len(pyrimid)):\n","    y_max, x_max = pyrimid[i].shape\n","    normalize = scalor ** (i - 1)\n","    y = 0\n","    while y < y_max - box_l:\n","      x = 0\n","      while x < x_max - box_w:\n","        sample = pyrimid[i][y:y+box_l, x:x+box_w]\n","        hog_des = get_hog_descriptors(np.array([sample * 255]))\n","        predi = human_model.predict(hog_des)[0, 1]\n","        # threshold for detection model\n","        if predi > 0.8:\n","          # detection box: [y_start, y_end, x_start, x_end, prediction_score]        \n","          box = [int(x * normalize) for x in (y, y+box_l, x, x+box_w)] + [predi]\n","          people.append(box)\n","        # shift 8 pixels \n","        x += 16\n","      y += 16\n","      \n","  good_boxes = non_max_supression(people, 0.4) # = people for not suppressed\n","  clas = {0: 'stand', 1: 'walk', 2: 'run'}\n","  \n","  for box in good_boxes:\n","    crop = cv2.resize(gray[box[0]:box[1], box[2]:box[3]], (64, 128))\n","    hogg = get_hog_descriptors(np.array([crop]))\n","    predi2 = pose_model.predict(hogg)[0].tolist()\n","    pose = clas[predi2.index(max(predi2))]\n","    # detection box: [y_start, y_end, x_start, x_end, prediction_score, pose] \n","    box.append(pose)\n","  return good_boxes\n","\n","\n","\n","def draw_detections(img, good_boxes):\n","  \"\"\" draw the detections onto the img with the good_boxes returned\n","  by find_detections\n","  \"\"\"\n","  for box in good_boxes:\n","    cv2.rectangle(img, (box[2], box[0]),\n","                       (box[3], box[1]),\n","                       (0, 0, 255), 1)\n","\n","    cv2.putText(img, box[5], (box[2],box[0]),\n","                       cv2.FONT_HERSHEY_PLAIN, 1.2, (255, 0, 0), 1)\n","  return img\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8gVshFigfvvn","colab_type":"text"},"cell_type":"markdown","source":["Section 4"]},{"metadata":{"id":"GLOIgsCjyFE3","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# image name\n","files = listdir(gdrive + runpath)\n","model = keras.models.load_model(gdrive + 'humanDectectionModel')\n","model2 = keras.models.load_model(gdrive + 'poseDectectionModel')\n","name = files[2]\n","img = cv2.imread(gdrive + runpath + '/' + name)\n","\n","img_plt = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","plt.imshow(img_plt)\n","plt.show()\n","\n","boxe = find_detections(img, model, model2, 1.3)\n","draw_detections(img, boxe)\n","img_plt = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","plt.imshow(img_plt)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YksdTVWWfxOs","colab_type":"text"},"cell_type":"markdown","source":["Section 5"]},{"metadata":{"id":"4L5PEtrSMEYx","colab_type":"code","colab":{}},"cell_type":"code","source":["vcap = cv2.VideoCapture(gdrive + 'TownCentreXVID.avi')\n","# Define the codec and create VideoWriter object\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter(gdrive + 'output.avi', fourcc, 25.0, (680, 383), True)\n","\n","counter = 0\n","good_boxes = []\n","while(counter < 600):\n","    # Capture frame-by-frame\n","    ret, frame = vcap.read()  \n","    if frame is None:\n","        print(\"Frame is None\")\n","        break\n","        \n","    frame = cv2.resize(frame, (680, 383))        \n","    counter += 1\n","    # detect people every 15 frames\n","    if counter % 6 == 0:\n","        print(\"detect\", counter)\n","        good_boxes = find_detections(frame, model, model2, 1.2)\n","    draw_detections(frame, good_boxes)\n","\n","    out.write(frame)\n","    # Display the resulting frame\n","    # cv2.imshow('frame',frame)\n","    # Press q to close the video windows before it ends if you want\n","    if cv2.waitKey(22) & 0xFF == ord('q'):\n","        break\n","\n","# When everything done, release the capture\n","vcap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","print(\"Video stop\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FLl2EYQZITqn","colab_type":"text"},"cell_type":"markdown","source":["Section 6 (this replaces Section 5)"]},{"metadata":{"id":"5-HV0cV-IQ2T","colab_type":"code","colab":{}},"cell_type":"code","source":["vcap = cv2.VideoCapture(gdrive + 'TownCentreXVID.avi')\n","# Define the codec and create VideoWriter object\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter(gdrive + 'output2.avi', fourcc, 25.0, (680, 383), True)\n","\n","counter = 0\n","good_boxes = []\n","multiTracker = cv2.MultiTracker_create()\n","while(counter < 600):\n","    # Capture frame-by-frame\n","    ret, frame = vcap.read()  \n","    if frame is None:\n","        print(\"Frame is None\")\n","        break\n","        \n","    frame = cv2.resize(frame, (680, 383))        \n","    counter += 1\n","    # detect people every 15 frames\n","    if counter % 50 == 0:\n","        print(\"detect\", counter)\n","        good_boxes = find_detections(frame, model, model2, 1.2)\n","        multiTracker = cv2.MultiTracker_create()\n","        for box in good_boxes:\n","          bbox = (box[2], box[3]-box[2], box[0], box[1]-box[0])\n","          multiTracker.add(cv2.TrackerCSRT_create(), frame, bbox)\n","    sucess, boxes = multiTracker.update(frame)\n","    for i, newbox in enumerate(boxes):\n","      good_boxes[i][0] = newbox[1]\n","      good_boxes[i][1] = newbox[1] + newbox[3]\n","      good_boxes[i][2] = newbox[0]\n","      good_boxes[i][3] = newbox[0] + newbox[2]\n","    draw_detections(frame, good_boxes)\n","\n","    out.write(frame)\n","    # Display the resulting frame\n","    # cv2.imshow('frame',frame)\n","    # Press q to close the video windows before it ends if you want\n","    if cv2.waitKey(22) & 0xFF == ord('q'):\n","        break\n","\n","# When everything done, release the capture\n","vcap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","print(\"Video stop\")"],"execution_count":0,"outputs":[]}]}